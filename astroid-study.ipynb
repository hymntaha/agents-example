{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "024b9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "import lime\n",
    "from lime import lime_tabular, submodular_pick\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display_html\n",
    "\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# show all columns in functions like head()\n",
    "pd.set_option('display.max_columns', None)\n",
    "# to reset option use: pd.reset_option('max_columns')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# funtion to remove outliers\n",
    "# defined to remove skewness from our plots\n",
    "def rem_out(df, columns):\n",
    "    \"\"\"\n",
    "    funtion to remove outliers\n",
    "    defined to remove skewness from our plots\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        q1 = df[column].quantile(0.25)\n",
    "        q3 = df[column].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - (1.5 * iqr)\n",
    "        upper_bound = q3 + (1.5 * iqr)\n",
    "        df = df[(df[column] > lower_bound) & (df[column] < upper_bound)]\n",
    "        return df\n",
    "\n",
    "def add_spines(colour = '#425169', linewidth = 2):\n",
    "    \"\"\"\n",
    "    Add beautiful spines to you plots\n",
    "    \"\"\"\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.spines['right'].set_visible(True)\n",
    "    ax.spines[['bottom', 'left', 'top', 'right']].set_color(colour)\n",
    "    ax.spines[['bottom', 'left', 'top', 'right']].set_linewidth(linewidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad998c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/astroid/dataset.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11501a34",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['condition_code', 'n_obs_used'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m num_cols = [\u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33me\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mi\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mom\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mad\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mper_y\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcondition_code\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mn_obs_used\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mH\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdiameter\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33malbedo\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmoid\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mn\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mper\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mma\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m cat_cols = [\u001b[33m'\u001b[39m\u001b[33mpha\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mneo\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Columns dropped from the original dataset:\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# [extent, GM, IR, BV, UB, G, rot_per](Because many values were missing)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# [spec_B, spec_T](Contained too many classes(34 each!!!) and lack of data)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# [class, data_arc](Factors that dont affect diameter))\u001b[39;00m\n\u001b[32m     10\u001b[39m df = df.dropna(subset=[\u001b[33m\"\u001b[39m\u001b[33mdiameter\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;66;03m# Removing rows with null diameter\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/langchain-course/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/langchain-course/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/langchain-course/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['condition_code', 'n_obs_used'] not in index\""
     ]
    }
   ],
   "source": [
    "columns=['a', 'e', 'i', 'om', 'w', 'q', 'ad', 'per_y', 'condition_code', 'n_obs_used', 'H', 'diameter', 'albedo', 'moid','n', 'per', 'ma', 'pha', 'neo']\n",
    "num_cols = ['a', 'e', 'i', 'om', 'w', 'q', 'ad', 'per_y', 'condition_code', 'n_obs_used', 'H', 'diameter', 'albedo', 'moid','n', 'per', 'ma']\n",
    "cat_cols = ['pha', 'neo']\n",
    "df = df[columns]\n",
    "# Columns dropped from the original dataset:\n",
    "# [extent, GM, IR, BV, UB, G, rot_per](Because many values were missing)\n",
    "# [spec_B, spec_T](Contained too many classes(34 each!!!) and lack of data)\n",
    "# [class, data_arc](Factors that dont affect diameter))\n",
    "\n",
    "df = df.dropna(subset=[\"diameter\"]) # Removing rows with null diameter\n",
    "df = df[pd.to_numeric(df['diameter'], errors='coerce').notnull()] # Removing non numeric values\n",
    "#df = df.interpolate() # Substituting Variables. Not a good idea :/ I know\n",
    "df = df.round(decimals=5) # Rounds Float Values\n",
    "\n",
    "dfnum = df[num_cols].astype(float)\n",
    "dfcat = df[cat_cols]\n",
    "df = pd.concat([dfnum, dfcat], axis=1)\n",
    "df = df.reset_index() # Resetting dataframe indexes\n",
    "df = df.drop(['index'], axis=1)\n",
    "\n",
    "df = pd.get_dummies(df, columns = ['pha', 'neo'])\n",
    "\n",
    "# important columns to diameter prediction\n",
    "df = df.dropna(subset=[\"H\", \"albedo\"])\n",
    "\n",
    "\"\"\"\"removing outliers with the help of Isolation forestðŸŒ²ðŸŒ³\"\"\"\n",
    "def iso_forest(df):\n",
    "    contamination = 0.05\n",
    "    iso_model = IsolationForest(contamination=contamination, n_estimators=1000, random_state=21)\n",
    "    yhat = iso_model.fit_predict(df)\n",
    "\n",
    "    # select all rows that are not outliers\n",
    "    mask = yhat != -1\n",
    "    df = df.iloc[mask]\n",
    "    return df\n",
    "\n",
    "df = iso_forest(df)\n",
    "# through plotting we identified a single point with high diameter that was distorting the distributions\n",
    "df = df.loc[df.diameter<200]\n",
    "\n",
    "# we found out that no values of true values of neo or pha columns make it into the final dataset\n",
    "df = df.drop(['neo_Y', 'neo_N', 'pha_Y', 'pha_N'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

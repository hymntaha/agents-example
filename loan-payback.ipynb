{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9307308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (593994, 13)\n",
      "Test Shape: (254569, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "train_df = pd.read_csv('data/playground-series-s5e11/train.csv')\n",
    "test_df = pd.read_csv('data/playground-series-s5e11/test.csv')\n",
    "orig = pd.read_csv('data/playground-series-s5e11/loan_dataset_20000.csv')\n",
    "\n",
    "print('Train Shape:', train_df.shape)\n",
    "print('Test Shape:', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7110d444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             id  annual_income  debt_to_income_ratio  credit_score  \\\n",
       "0            0       29367.99                 0.084           736   \n",
       "1            1       22108.02                 0.166           636   \n",
       "2            2       49566.20                 0.097           694   \n",
       "3            3       46858.25                 0.065           533   \n",
       "4            4       25496.70                 0.053           665   \n",
       "...        ...            ...                   ...           ...   \n",
       "593989  593989       23004.26                 0.152           703   \n",
       "593990  593990       35289.43                 0.105           559   \n",
       "593991  593991       47112.64                 0.072           675   \n",
       "593992  593992       76748.44                 0.067           740   \n",
       "593993  593993       48959.52                 0.096           752   \n",
       "\n",
       "        loan_amount  interest_rate  gender marital_status education_level  \\\n",
       "0           2528.42          13.67  Female         Single     High School   \n",
       "1           4593.10          12.92    Male        Married        Master's   \n",
       "2          17005.15           9.76    Male         Single     High School   \n",
       "3           4682.48          16.10  Female         Single     High School   \n",
       "4          12184.43          10.21    Male        Married     High School   \n",
       "...             ...            ...     ...            ...             ...   \n",
       "593989     20958.37          10.92  Female         Single     High School   \n",
       "593990      3257.24          14.62    Male         Single      Bachelor's   \n",
       "593991       929.27          14.13  Female        Married      Bachelor's   \n",
       "593992     16290.40           9.87    Male         Single      Bachelor's   \n",
       "593993      7707.73          10.31    Male        Married     High School   \n",
       "\n",
       "       employment_status        loan_purpose grade_subgrade  loan_paid_back  \n",
       "0          Self-employed               Other             C3             1.0  \n",
       "1               Employed  Debt consolidation             D3             0.0  \n",
       "2               Employed  Debt consolidation             C5             1.0  \n",
       "3               Employed  Debt consolidation             F1             1.0  \n",
       "4               Employed               Other             D1             1.0  \n",
       "...                  ...                 ...            ...             ...  \n",
       "593989          Employed            Business             C3             1.0  \n",
       "593990          Employed  Debt consolidation             F5             1.0  \n",
       "593991          Employed  Debt consolidation             C1             1.0  \n",
       "593992          Employed  Debt consolidation             B2             1.0  \n",
       "593993          Employed           Education             B3             1.0  \n",
       "\n",
       "[593994 rows x 13 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0332c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'loan_paid_back'  #boolean\n",
    "CATS = ['gender', 'marital_status', 'education_level', 'employment_status', 'loan_purpose', 'grade_subgrade']\n",
    "BASE = [col for col in train_df.columns if col not in ['id', TARGET]]\n",
    "\n",
    "train = train_df.copy()\n",
    "test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135a7529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 Orig Features Created!!\n",
      "33 Total Features.\n"
     ]
    }
   ],
   "source": [
    "ORIG = []\n",
    "\n",
    "for col in BASE:\n",
    "    mean_map = orig.groupby(col)[TARGET].mean()\n",
    "    new_mean_col_name = f\"orig_mean_{col}\"\n",
    "    mean_map.name = new_mean_col_name\n",
    "    \n",
    "    train = train.merge(mean_map, on=col, how='left')\n",
    "    test = test.merge(mean_map, on=col, how='left')\n",
    "    ORIG.append(new_mean_col_name)\n",
    "\n",
    "    new_count_col_name = f\"orig_count_{col}\"\n",
    "    count_map = orig.groupby(col).size().reset_index(name=new_count_col_name)\n",
    "    \n",
    "    train = train.merge(count_map, on=col, how='left')\n",
    "    test = test.merge(count_map, on=col, how='left')\n",
    "    ORIG.append(new_count_col_name)\n",
    "\n",
    "print(len(ORIG), 'Orig Features Created!!')\n",
    "\n",
    "FEATURES = BASE + ORIG\n",
    "print(len(FEATURES), 'Total Features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6457eee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split (with ORIG features): (475195, 33)\n",
      "Val split (with ORIG features): (118799, 33)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train[FEATURES], train[TARGET].astype(int), \n",
    "    test_size=0.2, random_state=42, stratify=train[TARGET]\n",
    ")\n",
    "\n",
    "print(f'Train split (with ORIG features): {X_train.shape}')\n",
    "print(f'Val split (with ORIG features): {X_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40917c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features (Pearson correlation with target):\n",
      "credit_score            0.234560\n",
      "annual_income           0.006326\n",
      "loan_amount            -0.003762\n",
      "interest_rate          -0.131184\n",
      "debt_to_income_ratio   -0.335680\n",
      "\n",
      "Top categorical associations (Cramer's V or fallback):\n",
      "employment_status    0.656820\n",
      "grade_subgrade       0.227867\n",
      "loan_purpose         0.025437\n",
      "education_level      0.025274\n",
      "gender               0.007202\n",
      "marital_status       0.001375\n",
      "\n",
      "Top features by absolute association strength with the target:\n",
      "employment_status       0.656820\n",
      "debt_to_income_ratio    0.335680\n",
      "credit_score            0.234560\n",
      "grade_subgrade          0.227867\n",
      "interest_rate           0.131184\n",
      "loan_purpose            0.025437\n",
      "education_level         0.025274\n",
      "gender                  0.007202\n",
      "annual_income           0.006326\n",
      "loan_amount             0.003762\n",
      "marital_status          0.001375\n"
     ]
    }
   ],
   "source": [
    "# numeric correlations\n",
    "numeric_cols = train[BASE].select_dtypes(include=[np.number]).columns.tolist()\n",
    "numeric_corr = pd.Series(dtype=float)\n",
    "if numeric_cols:\n",
    "    numeric_corr = train[numeric_cols].corrwith(train[TARGET].astype(int)).sort_values(ascending=False)\n",
    "\n",
    "# categorical associations (Cramer's V)\n",
    "cat_cols = [c for c in BASE if c not in numeric_cols]\n",
    "\n",
    "# try to use scipy for chi2_contingency; fallback to a safe zero if unavailable\n",
    "try:\n",
    "    from scipy.stats import chi2_contingency\n",
    "    def cramers_v(x, y):\n",
    "        confusion = pd.crosstab(x, y)\n",
    "        if confusion.size == 0:\n",
    "            return 0.0\n",
    "        chi2 = chi2_contingency(confusion)[0]\n",
    "        n = confusion.sum().sum()\n",
    "        if n == 0:\n",
    "            return 0.0\n",
    "        phi2 = chi2 / n\n",
    "        r, k = confusion.shape\n",
    "        # bias correction\n",
    "        phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "        rcorr = r - ((r-1)**2)/(n-1)\n",
    "        kcorr = k - ((k-1)**2)/(n-1)\n",
    "        denom = min((kcorr-1), (rcorr-1))\n",
    "        return (phi2corr / denom)**0.5 if denom > 0 else 0.0\n",
    "except Exception:\n",
    "    def cramers_v(x, y):\n",
    "        # fallback: compute association ratio by encoding categories to codes and using Pearson\n",
    "        x_codes = x.astype('category').cat.codes\n",
    "        return abs(x_codes.corr(y.astype(int)))\n",
    "\n",
    "cat_assoc = {}\n",
    "for c in cat_cols:\n",
    "    col = train[c].fillna('NA')\n",
    "    cat_assoc[c] = cramers_v(col, train[TARGET].astype(int))\n",
    "\n",
    "cat_series = pd.Series(cat_assoc).sort_values(ascending=False)\n",
    "\n",
    "# Display summaries\n",
    "print('Numeric features (Pearson correlation with target):')\n",
    "if not numeric_corr.empty:\n",
    "    print(numeric_corr.to_string())\n",
    "else:\n",
    "    print('  No numeric features found in BASE.')\n",
    "\n",
    "print('\\nTop categorical associations (Cramer\\'s V or fallback):')\n",
    "if not cat_series.empty:\n",
    "    print(cat_series.head(20).to_string())\n",
    "else:\n",
    "    print('  No categorical features found in BASE.')\n",
    "\n",
    "# combined ranking by absolute strength\n",
    "combined = pd.concat([\n",
    "    numeric_corr.abs().rename('strength'),\n",
    "    cat_series.abs().rename('strength')\n",
    "]).sort_values(ascending=False)\n",
    "\n",
    "print('\\nTop features by absolute association strength with the target:')\n",
    "print(combined.head(20).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e49d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization 1: Numeric correlations\n",
    "if not numeric_corr.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, max(4, len(numeric_corr) * 0.3)))\n",
    "    numeric_corr.plot(kind='barh', ax=ax, color=['green' if x > 0 else 'red' for x in numeric_corr])\n",
    "    ax.set_title('Pearson Correlations: Numeric Features vs Target', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Correlation Coefficient', fontsize=12)\n",
    "    ax.set_ylabel('Feature', fontsize=12)\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No numeric features to visualize.\")\n",
    "\n",
    "# Visualization 2: Categorical associations\n",
    "if not cat_series.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, max(4, len(cat_series) * 0.3)))\n",
    "    cat_series.plot(kind='barh', ax=ax, color='steelblue')\n",
    "    ax.set_title(\"Cramer's V: Categorical Features vs Target\", fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel(\"Cramer's V (Association Strength)\", fontsize=12)\n",
    "    ax.set_ylabel('Feature', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No categorical features to visualize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e953ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Combined importance \n",
    "if not combined.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, max(5, len(combined) * 0.25)))\n",
    "    top_n = min(20, len(combined))\n",
    "    top_combined = combined.head(top_n)\n",
    "    top_combined.plot(kind='barh', ax=ax, color='coral')\n",
    "    ax.set_title(f'Top {top_n} Features by Association Strength with Target', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Association Strength (Absolute Value)', fontsize=12)\n",
    "    ax.set_ylabel('Feature', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No features to visualize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_encoded = train[BASE].copy()\n",
    "\n",
    "le_dict = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    train_encoded[col] = le.fit_transform(train[col].fillna('NA'))\n",
    "    le_dict[col] = le\n",
    "\n",
    "train_encoded[TARGET] = train[TARGET].astype(int)\n",
    "\n",
    "corr_matrix = train_encoded.corr()\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "target_corr = corr_matrix[TARGET].sort_values(ascending=False)\n",
    "print(f'\\n{TARGET} in correlation (label encoded):')\n",
    "print(target_corr.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a9723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# preprocess function\n",
    "def preprocess_features(df, features, cat_cols, numeric_cols):\n",
    "    \"\"\"Prepare Categoric and Numerical Features\"\"\"\n",
    "    df_processed = df[features].copy()\n",
    "    \n",
    "    # Kategorik kolonlar\n",
    "    for col in cat_cols:\n",
    "        if col in df_processed.columns:\n",
    "            df_processed[col] = df_processed[col].fillna('NA').astype('category')\n",
    "    \n",
    "    # Numeric kolonlar\n",
    "    for col in numeric_cols:\n",
    "        if col in df_processed.columns:\n",
    "            df_processed[col] = df_processed[col].fillna(0)\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# select numerical colons\n",
    "numeric_cols_full = [col for col in FEATURES if col not in cat_cols]\n",
    "\n",
    "print(f'Total features: {len(FEATURES)}')\n",
    "print(f'  - BASE features: {len(BASE)}')\n",
    "print(f'  - ORIG features: {len(ORIG)}')\n",
    "print(f'Numeric features: {len(numeric_cols_full)}')\n",
    "print(f'Categorical features: {len(cat_cols)}')\n",
    "\n",
    "\n",
    "X_train_full = preprocess_features(train, FEATURES, cat_cols, numeric_cols_full)\n",
    "y_train_full = train[TARGET].astype(int)\n",
    "\n",
    "X_test = preprocess_features(test, FEATURES, cat_cols, numeric_cols_full)\n",
    "\n",
    "X_train_split = preprocess_features(X_train, FEATURES, cat_cols, numeric_cols_full)\n",
    "X_val_split = preprocess_features(X_val, FEATURES, cat_cols, numeric_cols_full)\n",
    "\n",
    "print(f'\\nTraining set: {X_train_full.shape}')\n",
    "print(f'Test set: {X_test.shape}')\n",
    "print(f'Train split: {X_train_split.shape}')\n",
    "print(f'Val split: {X_val_split.shape}')\n",
    "\n",
    "# XGBoost model parameters\n",
    "xgb_params = {\n",
    "    'n_estimators': 10000,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.010433357477511243,\n",
    "    'tree_method': 'hist',\n",
    "    'device': 'cuda',\n",
    "    'eval_metric': 'auc',\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': 42,\n",
    "    'min_child_weight': 20,\n",
    "    'subsample': 0.8879829126651821,\n",
    "    'colsample_bytree': 0.5543148418738543,\n",
    "    'gamma': 0.6845363006652688,\n",
    "    'reg_alpha': 0.2399421158144976,\n",
    "    'reg_lambda': 0.28254661049782354,\n",
    "    'enable_categorical': True,\n",
    "    'early_stopping_rounds': 100,\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "print('\\nXGBoost training contuinue...')\n",
    "model = XGBClassifier(**xgb_params)\n",
    "\n",
    "model.fit(\n",
    "    X_train_full, y_train_full,\n",
    "    eval_set=[(X_train_split, y_train), (X_val_split, y_val)],\n",
    "    verbose=1000\n",
    ")\n",
    "\n",
    "print('Model training completed!')\n",
    "\n",
    "# Predict on test set\n",
    "pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Prepare submission\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test[\"id\"],\n",
    "    TARGET: pred\n",
    "})\n",
    "\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(f'\\nSubmission file saved!: submission.csv')\n",
    "print(f'Submission shape: {submission.shape}')\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

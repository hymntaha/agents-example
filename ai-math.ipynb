{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f58c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFLINE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657140c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "import gc\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca0e0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer,BitsAndBytesConfig,AutoModelForCausalLM, TrainingArguments\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "# Text embedding / Texxt Splitter for RAG \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "\n",
    "# Adv RAG library \n",
    "\n",
    "# for evaluate  LLM \n",
    "import evaluate # require online \n",
    "# from deepeval.metrics import GEval\n",
    "# from deepeval.test_case import LLMTestCase\n",
    "# from deepeval.metrics import AnswerRelevancyMetric, ContextualPrecisionMetric , ContextualRelevancyMetric, ContextualRecallMetric\n",
    "import pytest\n",
    "# import trulens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3f6752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20826fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearMemory():\n",
    "    for _ in range(5):\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6461ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable/Disable Function\n",
    "FEW_SHOT_TEST= False#True\n",
    "USE_RAG = True#False#False #True#True\n",
    "USE_WANDB = False#True # for  LLM evalution and debug , track fine tuning performance\n",
    "USE_TRULENS = False # for LLM evalution\n",
    "USE_DEEPEVAL = False # for LLM evalution   (require openAI API key)\n",
    "USE_TRAIN =  True #True #False#True \n",
    "USE_INFER =  False # for submision prediction only , no test model \n",
    "if OFFLINE :\n",
    "    USE_WANDB = False # Wandb only support online  \n",
    "if device.type == \"cpu\": #requred GPU support for fine turning \n",
    "    USE_TRAIN= False\n",
    "\n",
    "if USE_WANDB:\n",
    "    # train report to  W&B tool\n",
    "    import wandb\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    reportTo= \"wandb\"\n",
    "    user_secrets = UserSecretsClient()\n",
    "    my_secret = user_secrets.get_secret(\"wandb_api_key\") \n",
    "    wandb.login(key=my_secret) # login \n",
    "else: \n",
    "    reportTo = \"none\"# None\n",
    "#     os.environ[\"WANDB_DISABLED\"] = True#“true”\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

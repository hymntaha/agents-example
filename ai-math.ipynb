{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f58c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFLINE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657140c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "import gc\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca0e0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer,BitsAndBytesConfig,AutoModelForCausalLM, TrainingArguments\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "# Text embedding / Texxt Splitter for RAG \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "\n",
    "# Adv RAG library \n",
    "\n",
    "# for evaluate  LLM \n",
    "import evaluate # require online \n",
    "# from deepeval.metrics import GEval\n",
    "# from deepeval.test_case import LLMTestCase\n",
    "# from deepeval.metrics import AnswerRelevancyMetric, ContextualPrecisionMetric , ContextualRelevancyMetric, ContextualRecallMetric\n",
    "import pytest\n",
    "# import trulens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3f6752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20826fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearMemory():\n",
    "    for _ in range(5):\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6461ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable/Disable Function\n",
    "FEW_SHOT_TEST= False#True\n",
    "USE_RAG = True#False#False #True#True\n",
    "USE_WANDB = False#True # for  LLM evalution and debug , track fine tuning performance\n",
    "USE_TRULENS = False # for LLM evalution\n",
    "USE_DEEPEVAL = False # for LLM evalution   (require openAI API key)\n",
    "USE_TRAIN =  True #True #False#True \n",
    "USE_INFER =  False # for submision prediction only , no test model \n",
    "if OFFLINE :\n",
    "    USE_WANDB = False # Wandb only support online  \n",
    "if device.type == \"cpu\": #requred GPU support for fine turning \n",
    "    USE_TRAIN= False\n",
    "\n",
    "if USE_WANDB:\n",
    "    # train report to  W&B tool\n",
    "    import wandb\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    reportTo= \"wandb\"\n",
    "    user_secrets = UserSecretsClient()\n",
    "    my_secret = user_secrets.get_secret(\"wandb_api_key\") \n",
    "    wandb.login(key=my_secret) # login \n",
    "else: \n",
    "    reportTo = \"none\"# None\n",
    "#     os.environ[\"WANDB_DISABLED\"] = True#“true”\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_TRULENS:\n",
    "    from trulens_eval import Tru\n",
    "    tru = Tru()\n",
    "    tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c26aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reportTo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7040ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "device.type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29622116",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == \"cuda\" and USE_TRAIN == True: #requred GPU support\n",
    "    # for LoRA fine tuning\n",
    "    from trl import SFTTrainer\n",
    "    from peft import LoraConfig, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19ebffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleSubmitFile = \"/kaggle/input/ai-mathematical-olympiad-prize/sample_submission.csv\"\n",
    "trainFile = \"/kaggle/input/ai-mathematical-olympiad-prize/train.csv\"\n",
    "testFile = \"/kaggle/input/ai-mathematical-olympiad-prize/test.csv\"\n",
    "mathQSATrainFile = \"/kaggle/input/math-qsa-dataset/train.csv\"\n",
    "mathQSATestFile = \"/kaggle/input/math-qsa-dataset/test.csv\"\n",
    "gsm8kTrainFile = \"/kaggle/input/gsm8k-grade-school-math-8k-dataset-for-llm/gsm8k/main/train-00000-of-00001.parquet\"\n",
    "gsm8kTestFile = \"/kaggle/input/gsm8k-grade-school-math-8k-dataset-for-llm/gsm8k/main/test-00000-of-00001.parquet\"\n",
    "mathQATrainFile = \"/kaggle/input/math-qa-for-aqua-rat-dataset/MathQA/train.json\"\n",
    "mathQATestFile = \"/kaggle/input/math-qa-for-aqua-rat-dataset/MathQA/test.json\"\n",
    "orcaMath200kFile = \"/kaggle/input/microsoftorca-math-word-problems-200k/orca-math-word-problems-200k/data/train-00000-of-00001.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "clearMemory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e4ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.read_csv(trainFile)\n",
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f44fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.iloc[7][\"answer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedf9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = pd.read_csv(testFile)\n",
    "testDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6bc5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainQSADF = pd.read_csv(mathQSATrainFile)\n",
    "trainQSADF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454afd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainQSADF[\"problem\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcdf7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainQSADF.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5835c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainQADF= pd.read_json(mathQATrainFile)\n",
    "trainQADF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467776f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainQADF[\"options\"][5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGSM8KDF =pd.read_parquet(gsm8kTrainFile)\n",
    "trainGSM8KDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGSM8KDF.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGSM8KDF.iloc[0][\"answer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testGSM8KDF = pd.read_parquet(gsm8kTestFile)\n",
    "testGSM8KDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c19547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testGSM8KDF[\"answer\"][12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOracMath200kDF = pd.read_parquet(orcaMath200kFile)\n",
    "trainOracMath200kDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6999b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainOracMath200kDF[\"answer\"].iloc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220fc295",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF[\"problem\"][9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfd3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning data set\n",
    "# trainDF[\"problem\"] = trainDF[\"problem\"].str.replace(\"$\", '')\n",
    "# trainDF[\"problem\"] = trainDF[\"problem\"].str.replace(\"\\\\vert\", '|')\n",
    "# trainDF[\"problem\"] = trainDF[\"problem\"].str.replace(\"\\\\left\", '')\n",
    "# trainDF[\"problem\"] = trainDF[\"problem\"].str.replace(\"\\\\right\", '')\n",
    "# trainDF[\"problem\"] = trainDF[\"problem\"].str.replace(\"\\\\mathbb\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa32dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainDF[\"problem\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e25de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainDF[\"answer\"][1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
